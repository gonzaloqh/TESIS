{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminacion Registros Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_tsv(input_file, output_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n",
    "    \n",
    "    duplicates = df.duplicated()\n",
    "    num_duplicates = duplicates.sum()\n",
    "    print(f\"Número de registros duplicados: {num_duplicates}\")\n",
    "    \n",
    "    df_unique = df.drop_duplicates()\n",
    "    df_unique.to_csv(output_file, sep='\\t', index=False, header=False)\n",
    "    print(f\"Registros únicos guardados en '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_26124\\224243022.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros duplicados: 41532\n",
      "Registros únicos guardados en 'paraphrases_no_dup.tsv'\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'paraphrases.tsv'\n",
    "output_tsv = 'paraphrases_no_dup.tsv'\n",
    "process_tsv(input_tsv, output_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_26124\\224243022.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros duplicados: 84408\n",
      "Registros únicos guardados en 'contradictions_no_dup.tsv'\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'contradictions.tsv'\n",
    "output_tsv = 'contradictions_no_dup.tsv'\n",
    "process_tsv(input_tsv, output_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision valores nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros con al menos un valor NaN:\n",
      "                   Phrase Paraphrase/Contradiction               Type  \\\n",
      "862515      null and void                      NaN  ForwardEntailment   \n",
      "1679279     null and void                      NaN  ForwardEntailment   \n",
      "1712410     null and void                      NaN  ForwardEntailment   \n",
      "2033918  be null and void                      NaN        Equivalence   \n",
      "\n",
      "            Score  \n",
      "862515   0.518725  \n",
      "1679279  0.506134  \n",
      "1712410  0.505806  \n",
      "2033918  0.731919  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_iterator = pd.read_csv(\"paraphrases_no_dup.tsv\", sep=\"\\t\")\n",
    "rows_with_nan = tsv_iterator[tsv_iterator.isnull().any(axis=1)]\n",
    "print(\"Registros con al menos un valor NaN:\")\n",
    "print(rows_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con valores NaN reemplazados por 'Nan' y archivo actualizado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_iterator = pd.read_csv(\"paraphrases_no_dup.tsv\", sep=\"\\t\")\n",
    "tsv_iterator_filled = tsv_iterator.fillna(\"Nan\")\n",
    "tsv_iterator_filled.to_csv(\"paraphrases_no_dup.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"DataFrame con valores NaN reemplazados por 'Nan' y archivo actualizado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros con al menos un valor NaN:\n",
      "Empty DataFrame\n",
      "Columns: [Phrase, Paraphrase/Contradiction, Type, Score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_iterator = pd.read_csv(\"contradictions_no_dup.tsv\", sep=\"\\t\")\n",
    "rows_with_nan = tsv_iterator[tsv_iterator.isnull().any(axis=1)]\n",
    "print(\"Registros con al menos un valor NaN:\")\n",
    "print(rows_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_iterator = pd.read_csv(\"contradictions_no_dup.tsv\", sep=\"\\t\")\n",
    "tsv_iterator_filled = tsv_iterator.fillna(\"Nan\")\n",
    "tsv_iterator_filled.to_csv(\"contradictions_no_dup.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"DataFrame con valores NaN reemplazados por 'Nan' y archivo actualizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traduccion del corpus sin repetidos exactos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-translate in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.19.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (2.24.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-translate) (2.35.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.4 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-translate) (2.4.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-translate) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-translate) (5.29.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-translate) (0.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (1.69.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-translate) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-translate) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-translate) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-translate) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gonzalo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-translate) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        project_id=\"tesis-448119\"\n",
    "        client = translate.TranslationServiceClient()\n",
    "        location = \"global\"\n",
    "        parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "        response = client.translate_text(\n",
    "            request={\n",
    "                \"parent\": parent,\n",
    "                \"contents\": text,\n",
    "                \"mime_type\": \"text/plain\",\n",
    "                \"source_language_code\": \"en-US\",\n",
    "                \"target_language_code\": \"es\",\n",
    "            }\n",
    "        )\n",
    "        translated_texts = [translation.translated_text for translation in response.translations]\n",
    "        return translated_texts\n",
    "    except  Exception as f:\n",
    "        print(\"error: \", {f})\n",
    "\n",
    "\n",
    "#print(translate_text(['Hello', 'dog', 'bread', 'your', 'bee', 'epson', 'co-chairman', 'google']))\n",
    "#print(translate_text(['is considered to be', 'be considered to be', ', and therefore we', ', it is necessary to', 'and i am sure that', ', the committee recommended that', 'to develop a', 'telecommunications sector', 'decided to set', ', are responsible', 'legal proceedings .', 'aims and objectives of the', 'aims and objectives of the', 'sufficiently precise', ''nan'', 'country to country', 'therefore concludes that', 'of the commission is', 'and boost the', 'in addition , there was', 'in addition , there is']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "# Función para traducir en bloques de 50 filas\n",
    "def translate_tsv_in_batches(tsv_file: str, output_file: str, batch_size: int = 100):\n",
    "    try:\n",
    "        # Leer el archivo TSV en modo iterativo\n",
    "        tsv_iterator = pd.read_csv(tsv_file, sep=\"\\t\", chunksize=batch_size)\n",
    "\n",
    "        # Crear un archivo de salida vacío\n",
    "        with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "            header_written = False\n",
    "\n",
    "            # Obtener el número total de filas para la barra de progreso\n",
    "            total_rows = sum(1 for _ in open(tsv_file, 'r')) - 1  # Restar 1 por el encabezado\n",
    "            total_chunks = total_rows // batch_size + (1 if total_rows % batch_size > 0 else 0)\n",
    "\n",
    "            # Crear la barra de progreso\n",
    "            with tqdm(total=total_chunks, desc=\"Procesando bloques\") as pbar:\n",
    "                # Procesar cada bloque\n",
    "                for chunk in tsv_iterator:\n",
    "                    # Verificar si las columnas necesarias existen\n",
    "                    if not {'Phrase', 'Paraphrase/Contradiction'}.issubset(chunk.columns):\n",
    "                        raise ValueError(\"El archivo TSV debe contener las columnas 'Phrase' y 'Paraphrase/Contradiction'\")\n",
    "\n",
    "                    # Obtener textos de 'Phrase' y 'Paraphrase/Contradiction'\n",
    "                    texts_to_translate = chunk['Phrase'].tolist() + chunk['Paraphrase/Contradiction'].tolist()\n",
    "                    translated_texts = translate_text(texts_to_translate)\n",
    "\n",
    "                    if(len(texts_to_translate) != len(translated_texts)):\n",
    "                        print(\"¡El tamaño de los arrays no coincide!\")\n",
    "                        break\n",
    "                    translated_textA = translated_texts[:len(chunk)]\n",
    "                    translated_textB = translated_texts[len(chunk):]\n",
    "\n",
    "                    chunk['Phrase'] = translated_textA\n",
    "                    chunk['Paraphrase/Contradiction'] = translated_textB\n",
    "\n",
    "                    # Escribir el chunk traducido en el archivo de salida\n",
    "                    if not header_written:\n",
    "                        chunk.to_csv(out_file, sep=\"\\t\", index=False, mode='w', header=True, lineterminator='\\n')\n",
    "                        header_written = True\n",
    "                    else:\n",
    "                        chunk.to_csv(out_file, sep=\"\\t\", index=False, mode='a', header=False, lineterminator='\\n')\n",
    "\n",
    "                    # Actualizar la barra de progreso\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    except Exception as f:\n",
    "        print(\"Error:\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando bloques: 100%|██████████| 249/249 [02:00<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "translate_tsv_in_batches(\"paraphrases_no_dup.tsv\", \"paraphrases_translated.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando bloques: 100%|██████████| 463/463 [03:52<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "translate_tsv_in_batches(\"contradictions_no_dup.tsv\", \"contradictions_translated.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de registros duplicados con distintos scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_similar_records(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n",
    "    \n",
    "    grouped = df.groupby(['textA', 'textB', 'type'])['score'].nunique()\n",
    "    conflicting_groups = grouped[grouped > 1]\n",
    "    \n",
    "    similar_records = df[df.set_index(['textA', 'textB', 'type']).index.isin(conflicting_groups.index)]\n",
    "    print(len(similar_records))\n",
    "    print(similar_records.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_10800\\857441086.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326748\n",
      "            textA       textB         type               score\n",
      "2  not-for-profit  non-profit  Equivalence  0.7606575999999999\n",
      "4         muslims      muslim  Equivalence           0.6259608\n",
      "6       modelling    modeling  Equivalence            0.683473\n",
      "7        modeling   modelling  Equivalence  0.6833613999999999\n",
      "8          uganda     ugandan  Equivalence            0.600723\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'paraphrases_no_dup.tsv'\n",
    "find_similar_records(input_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_10800\\857441086.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4712125\n",
      "           textA        textB           type               score\n",
      "1        hi-tech     low-tech  contradiction           0.3013428\n",
      "3  decentralised  centralized  contradiction  0.3109483999999999\n",
      "4  decentralised   centralize  contradiction  0.3109483999999999\n",
      "5  decentralised  concentrate  contradiction  0.3109483999999999\n",
      "6        handled   handleless  contradiction  0.3120763999999999\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'contradictions_no_dup.tsv'\n",
    "find_similar_records(input_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_similar_records(input_file, output_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n",
    "    \n",
    "    df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
    "    merged = df.groupby(['textA', 'textB', 'type'], as_index=False).agg({'score': 'mean'})\n",
    "    \n",
    "    merged.to_csv(output_file, sep='\\t', index=False, header=False)\n",
    "    \n",
    "    print(f\"Archivo actualizado guardado en: {output_file}\")\n",
    "    print(f\"Total de registros en el archivo actualizado: {len(merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_10800\\2296289563.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo actualizado guardado en: paraphrases_no_dup.tsv\n",
      "Total de registros en el archivo actualizado: 3310055\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'paraphrases.tsv'\n",
    "output_tsv = 'paraphrases_clean.tsv'\n",
    "merge_similar_records(input_tsv, output_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\AppData\\Local\\Temp\\ipykernel_10800\\2296289563.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t', header=None, names=['textA', 'textB', 'type', 'score'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo actualizado guardado en: contradictions_clean.tsv\n",
      "Total de registros en el archivo actualizado: 837520\n"
     ]
    }
   ],
   "source": [
    "input_tsv = 'contradictions.tsv'\n",
    "output_tsv = 'contradictions_clean.tsv'\n",
    "merge_similar_records(input_tsv, output_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
